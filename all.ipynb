{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from utils import (\n",
    "    preprocess_text, train, evaluate, predict, nltk_get_sentiment,\n",
    "    tfid_predict\n",
    ")\n",
    "from llm_utils import LLM_predict\n",
    "nltk.download('all')\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Download latest version\n",
    "    path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    df = pd.read_csv(path + \"/IMDB Dataset.csv\").iloc[:20]\n",
    "    df['sentiment'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "\n",
    "    \n",
    "    tqdm.pandas()\n",
    "    # clean/preprocess the review text\n",
    "    df['text_cleaned'] = df['review'].progress_apply(preprocess_text)\n",
    "\n",
    "    # df['nltk_sentiment'] = df['review_cleaned'].progress_apply(nltk_get_sentiment)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['text_cleaned'], df['sentiment'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"---------> LLM evaluation\")\n",
    "    llm_y_pred = LLM_predict(X_train, y_train, X_test)\n",
    "    evaluate(llm_y_pred, y_test)\n",
    "\n",
    "    \n",
    "    print(\"------------> TFID evaluation:\")\n",
    "    tfid_y_pred = tfid_predict(X_train, y_train, X_test) \n",
    "    evaluate(tfid_y_pred, y_test)\n",
    "    \n",
    "    print(\"------------> nltk sentiment evaluation:\")\n",
    "    nltk_sentiment_y_pred = [nltk_get_sentiment(txt) for txt in X_test]\n",
    "    evaluate(nltk_sentiment_y_pred, y_test)\n",
    "\n",
    "    print(\"------------> nltk sentiment & TFID evaluation:\")\n",
    "    mixed_y_pred = tfid_y_pred * nltk_sentiment_y_pred\n",
    "    evaluate(mixed_y_pred, y_test)\n",
    "    \n",
    "    # # Example prediction\n",
    "    # sample_text = \"This product is fantastic!\"\n",
    "    # result = predict(sample_text, tfid_vectorizer, classifier)\n",
    "    # print(f\"\\nSample prediction for '{sample_text}':\")\n",
    "    # print(f\"Sentiment: {result['sentiment']}\")\n",
    "    # print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "nltk.download('all')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# create preprocess_text function\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Lemmatize the tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text\n",
    "\n",
    "def nltk_get_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "def train(X_train, y_train, classifier):\n",
    "    \"\"\"Train the sentiment analysis model\"\"\"\n",
    "    print(\"Training model...\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "def evaluate(y_pred, y_test):\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\n F1-Score = \", f1_score(y_test, y_pred))\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def predict(text, vectorizer, classifier):\n",
    "    \"\"\"Predict sentiment for new text\"\"\"\n",
    "    processed_text = preprocess_text(text)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    prediction = classifier.predict(vectorized_text)\n",
    "    probability = classifier.predict_proba(vectorized_text)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': 'positive' if prediction[0] == 1 else 'negative',\n",
    "        'confidence': max(probability[0])\n",
    "    }\n",
    "\n",
    "def tfid_predict(X_train, y_train, X_test):\n",
    "    tfid_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    # Vectorize text\n",
    "    print(\"Vectorizing text...\")\n",
    "    X_train_vec = tfid_vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = tfid_vectorizer.transform(X_test)\n",
    "\n",
    "    train(X_train_vec, y_train, classifier)\n",
    "\n",
    "    return classifier.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('device = ', device)\n",
    "\n",
    "\n",
    "def generate_prompt(input):\n",
    "    return f\"\"\"Please perform Sentiment Classification task.\n",
    "            Given the sentence, assign a sentiment label\n",
    "            from ['negative', 'positive']. Return label only\n",
    "            without any other text.\n",
    "            Sentence: Oh , and more entertaining, too.\n",
    "            Label: positive\n",
    "            Sentence: If you 're not a fan , it might be like\n",
    "            trying to eat Brussels sprouts.\n",
    "            Label: negative\n",
    "            Sentence: {input}.\n",
    "            Label: \"\"\"\n",
    "\n",
    "\n",
    "def generate_text_from_prompt(model, tokenizer, prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def LLM_predict(X_train, y_train, X_test):\n",
    "    model_name = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        # torch_dtype=\"auto\",\n",
    "        # device_map=\"auto\"\n",
    "        low_cpu_mem_usage=True\n",
    "    ).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    output_sentiments = [\n",
    "        generate_text_from_prompt(model, tokenizer, generate_prompt(txt)) for txt in X_test\n",
    "    ]\n",
    "    print(output_sentiments)\n",
    "    return np.where(np.array(output_sentiments)=='positive', 1, 0)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1 (main, Dec  3 2024, 17:59:52) [Clang 16.0.0 (clang-1600.0.26.4)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5b69e2d74daef99974fb039a63f35fa3ce55a4f162fb7c62f2dfe9a980ea223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
